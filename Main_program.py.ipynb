{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing libraries required \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sohel/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#these are custome classes created by me to split data into training and testing sets\n",
    "#and for regression model\n",
    "from LinearRegressionModel import Regressor\n",
    "from Preprocess import Splitter\n",
    "from Preprocess import Encoder\n",
    "en=Encoder()\n",
    "sp=Splitter()\n",
    "reg=Regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset to our program\n",
    "dataset=pd.read_csv('50_Startups.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deviding dataset into dependant and independant data\n",
    "x=dataset.loc[:,['R&D Spend','Administration','Marketing Spend','State']]\n",
    "y=dataset.loc[:,['Profit']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a no of row you have to considered for taking mean49\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.array(x)\n",
    "n=int(input(\"enter a no of row you have to considered for taking mean\"))\n",
    "m=[]\n",
    "for i in range(0,n):\n",
    "    m.append(np.mean(x[i,0:3]))\n",
    "    \n",
    "y=np.array(y)  \n",
    "z=y[0:49,:]\n",
    "\n",
    "plt.scatter(m,z,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#accoriding to above plotting of mean of independant data with dependant data it is clear that our data is linearlly\n",
    "#distributed,so we can apply linear regression for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend  State\n",
       "0  165349.20       136897.80        471784.10      0\n",
       "1  162597.70       151377.59        443898.53      1\n",
       "2  153441.51       101145.55        407934.54      0\n",
       "3  144372.41       118671.85        383199.62      0\n",
       "4  142107.34        91391.77        366168.42      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting dummy variable to handle catagorical data\n",
    "x=dataset.loc[:,['R&D Spend','Administration','Marketing Spend','State']]\n",
    "\n",
    "x['State']=en.encoder(x['State'])\n",
    "x['State']=x['State'].values\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deviding data into training and testing sets\n",
    "x_train,x_test,y_train,y_test=sp.decomposition(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fitting trained data to regression model\n",
    "regressor=reg.regressor(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting fot x_test\n",
    "y_pred=regressor.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#upto this we done with the fitting model to regression.But it is not giving that much accuracy i.e 93.93%\n",
    "#to make our model more accurate we need to optimize our metrics of features.To optimize metrics of features \n",
    "#backward elimination will be helpfull.In backward elimination 1st we set p value(S.L=0.05 in our case).All\n",
    "#attrubute having p value greater than 0.05 we have to eliminate them.Finally we make our matrics of fearure \n",
    "#optimal.\n",
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to perform backward elimination we need following librery to be import\n",
    "import statsmodels.formula.api as sm\n",
    "#now we need to add one more colomn to our metrics of feature i.e colomn of ones\n",
    "x=np.append(arr=np.ones((50,1)).astype(int),values=x,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   217.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>8.51e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:52</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1061.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1070.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.016e+04</td> <td> 6798.992</td> <td>    7.377</td> <td> 0.000</td> <td> 3.65e+04</td> <td> 6.39e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.046</td> <td>   17.646</td> <td> 0.000</td> <td>    0.714</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.052</td> <td>   -0.520</td> <td> 0.606</td> <td>   -0.131</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.017</td> <td>    1.627</td> <td> 0.111</td> <td>   -0.006</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  -70.2265</td> <td> 2828.752</td> <td>   -0.025</td> <td> 0.980</td> <td>-5767.625</td> <td> 5627.172</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.785</td> <th>  Durbin-Watson:     </th> <td>   1.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.568</td> <th>  Cond. No.          </th> <td>1.44e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     217.2\n",
       "Date:                Sun, 24 Feb 2019   Prob (F-statistic):           8.51e-29\n",
       "Time:                        12:36:52   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1061.\n",
       "Df Residuals:                      45   BIC:                             1070.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.016e+04   6798.992      7.377      0.000    3.65e+04    6.39e+04\n",
       "x1             0.8057      0.046     17.646      0.000       0.714       0.898\n",
       "x2            -0.0268      0.052     -0.520      0.606      -0.131       0.077\n",
       "x3             0.0272      0.017      1.627      0.111      -0.006       0.061\n",
       "x4           -70.2265   2828.752     -0.025      0.980   -5767.625    5627.172\n",
       "==============================================================================\n",
       "Omnibus:                       14.785   Durbin-Watson:                   1.281\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.242\n",
       "Skew:                          -0.949   Prob(JB):                     2.44e-05\n",
       "Kurtosis:                       5.568   Cond. No.                     1.44e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.44e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now our process of making metrics of features more optimla begins\n",
    "x_opt=x[:,[0,1,2,3,4]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with reference to above summary colomn x4 is having max p value,so we have to reduce it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   296.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>4.53e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:54</td>     <th>  Log-Likelihood:    </th> <td> -525.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1066.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.012e+04</td> <td> 6572.353</td> <td>    7.626</td> <td> 0.000</td> <td> 3.69e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8057</td> <td>    0.045</td> <td>   17.846</td> <td> 0.000</td> <td>    0.715</td> <td>    0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0268</td> <td>    0.051</td> <td>   -0.526</td> <td> 0.602</td> <td>   -0.130</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0272</td> <td>    0.016</td> <td>    1.655</td> <td> 0.105</td> <td>   -0.006</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.838</td> <th>  Durbin-Watson:     </th> <td>   1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.949</td> <th>  Prob(JB):          </th> <td>2.21e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.586</td> <th>  Cond. No.          </th> <td>1.40e+06</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     296.0\n",
       "Date:                Sun, 24 Feb 2019   Prob (F-statistic):           4.53e-30\n",
       "Time:                        12:36:54   Log-Likelihood:                -525.39\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      46   BIC:                             1066.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.012e+04   6572.353      7.626      0.000    3.69e+04    6.34e+04\n",
       "x1             0.8057      0.045     17.846      0.000       0.715       0.897\n",
       "x2            -0.0268      0.051     -0.526      0.602      -0.130       0.076\n",
       "x3             0.0272      0.016      1.655      0.105      -0.006       0.060\n",
       "==============================================================================\n",
       "Omnibus:                       14.838   Durbin-Watson:                   1.282\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.442\n",
       "Skew:                          -0.949   Prob(JB):                     2.21e-05\n",
       "Kurtosis:                       5.586   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=x[:,[0,1,2,3]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from summary above colomn x2 is having more p value then have to remove it from our x_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   450.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>2.16e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:56</td>     <th>  Log-Likelihood:    </th> <td> -525.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1057.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.698e+04</td> <td> 2689.933</td> <td>   17.464</td> <td> 0.000</td> <td> 4.16e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7966</td> <td>    0.041</td> <td>   19.266</td> <td> 0.000</td> <td>    0.713</td> <td>    0.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0299</td> <td>    0.016</td> <td>    1.927</td> <td> 0.060</td> <td>   -0.001</td> <td>    0.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.677</td> <th>  Durbin-Watson:     </th> <td>   1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.939</td> <th>  Prob(JB):          </th> <td>2.54e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.575</td> <th>  Cond. No.          </th> <td>5.32e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.948\n",
       "Method:                 Least Squares   F-statistic:                     450.8\n",
       "Date:                Sun, 24 Feb 2019   Prob (F-statistic):           2.16e-31\n",
       "Time:                        12:36:56   Log-Likelihood:                -525.54\n",
       "No. Observations:                  50   AIC:                             1057.\n",
       "Df Residuals:                      47   BIC:                             1063.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.698e+04   2689.933     17.464      0.000    4.16e+04    5.24e+04\n",
       "x1             0.7966      0.041     19.266      0.000       0.713       0.880\n",
       "x2             0.0299      0.016      1.927      0.060      -0.001       0.061\n",
       "==============================================================================\n",
       "Omnibus:                       14.677   Durbin-Watson:                   1.257\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               21.161\n",
       "Skew:                          -0.939   Prob(JB):                     2.54e-05\n",
       "Kurtosis:                       5.575   Cond. No.                     5.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=x[:,[0,1,3]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now x2 is having more p value so we vae to remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   849.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Feb 2019</td> <th>  Prob (F-statistic):</th> <td>3.50e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:58</td>     <th>  Log-Likelihood:    </th> <td> -527.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1059.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1063.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.903e+04</td> <td> 2537.897</td> <td>   19.320</td> <td> 0.000</td> <td> 4.39e+04</td> <td> 5.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.8543</td> <td>    0.029</td> <td>   29.151</td> <td> 0.000</td> <td>    0.795</td> <td>    0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13.727</td> <th>  Durbin-Watson:     </th> <td>   1.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  18.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.911</td> <th>  Prob(JB):          </th> <td>9.44e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.361</td> <th>  Cond. No.          </th> <td>1.65e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.947\n",
       "Model:                            OLS   Adj. R-squared:                  0.945\n",
       "Method:                 Least Squares   F-statistic:                     849.8\n",
       "Date:                Sun, 24 Feb 2019   Prob (F-statistic):           3.50e-32\n",
       "Time:                        12:36:58   Log-Likelihood:                -527.44\n",
       "No. Observations:                  50   AIC:                             1059.\n",
       "Df Residuals:                      48   BIC:                             1063.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.903e+04   2537.897     19.320      0.000    4.39e+04    5.41e+04\n",
       "x1             0.8543      0.029     29.151      0.000       0.795       0.913\n",
       "==============================================================================\n",
       "Omnibus:                       13.727   Durbin-Watson:                   1.116\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.536\n",
       "Skew:                          -0.911   Prob(JB):                     9.44e-05\n",
       "Kurtosis:                       5.361   Cond. No.                     1.65e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.65e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt=x[:,[0,1]]\n",
    "regressor_OLS=sm.OLS(endog=y,exog=x_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in above summary every colomn having p value less than our significance p value i.e 0.05\n",
    "#so our optimal metrics of features is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we have to split x_opt into training and testing sets\n",
    "x_train_opt,x_test_opt,y_train,y_test=sp.decomposition(x_opt,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we have to fit optimal metrics of features to our regression mode\n",
    "regressor=reg.regressor(x_train_opt,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here we will predict values for y_test\n",
    "y_optimal_pred=regressor.predict(x_test_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103282.38]\n",
      " [144259.4 ]\n",
      " [146121.95]\n",
      " [ 77798.83]\n",
      " [191050.39]\n",
      " [105008.31]\n",
      " [ 81229.06]\n",
      " [ 97483.56]\n",
      " [110352.25]\n",
      " [166187.94]]\n"
     ]
    }
   ],
   "source": [
    "#thiese are the original values of y_test that we provided to algorithm for x_test\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103904]\n",
      " [132759]\n",
      " [133569]\n",
      " [ 72914]\n",
      " [179629]\n",
      " [115168]\n",
      " [ 67116]\n",
      " [ 98157]\n",
      " [114758]\n",
      " [169065]]\n"
     ]
    }
   ],
   "source": [
    "#these are the 1st predicted values for x_test\n",
    "print(y_pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104667]\n",
      " [134150]\n",
      " [135207]\n",
      " [ 72170]\n",
      " [179090]\n",
      " [109824]\n",
      " [ 65644]\n",
      " [100481]\n",
      " [111431]\n",
      " [169438]]\n"
     ]
    }
   ],
   "source": [
    "#these are the predicted values for x_test after performimg backward elimination\n",
    "print(y_optimal_pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.93968220927191%\n"
     ]
    }
   ],
   "source": [
    "#r-squared accuracy of 1st predicted values of x_test with respect to original values i.e y_test\n",
    "from sklearn import metrics\n",
    "accuracy=metrics.r2_score(y_test, y_pred)\n",
    "print('{}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.93968220927191%\n"
     ]
    }
   ],
   "source": [
    "#r-squared accuracy of predicted values of x_test after performing backward elimination with respect to y_test \n",
    "from sklearn import metrics\n",
    "accuracy2=metrics.r2_score(y_test, y_optimal_pred)\n",
    "print('{}%'.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
